@article{flowibr,
    title = {{FlowIBR}: {Leveraging} {Pre}-{Training} for {Efficient} {Neural} {Image}-{Based} {Rendering} of {Dynamic} {Scenes}},
    shorttitle = {{FlowIBR}},
    author = {Büsching, Marcel and Bengtson, Josef and Nilsson, David and Björkman, Mårten},
    journal={arXiv preprint, arXiv.2309.05418},
    abstract = {We introduce a novel approach for monocular novel view synthesis of dynamic scenes. Existing techniques already show impressive rendering quality but tend to focus on optimization within a single scene without leveraging prior knowledge. This limitation has been primarily attributed to the lack of datasets of dynamic scenes available for training and the diversity of scene dynamics. Our method FlowIBR circumvents these issues by integrating a neural image-based rendering method, pre-trained on a large corpus of widely available static scenes, with a per-scene optimized scene flow field. Utilizing this flow field, we bend the camera rays to counteract the scene dynamics, thereby presenting the dynamic scene as if it were static to the rendering network. The proposed method reduces per-scene optimization time by an order of magnitude, achieving comparable results to existing methods - all on a single consumer-grade GPU.},
    month = sep,
    year = {2023},
    html = {https://flowibr.github.io},
    url = {https://flowibr.github.io},
    selected={true},
    abbr={arxiv},
    preview={flowibr.gif}
}


@article{longhini2024distilling,
title={Distilling Semantic Features for 3D Cloth Representations from Vision Foundation Models},
author={Longhini, Alberta and Büsching, Marcel and Duisterhof, Bardienus Pieter and Jeffrey Ichnowski and Björkman, Mårten and Kragic, Danica},
journal={ICRA 2024 Workshop on 3D Visual Representations for Robot Manipulation},
abstract = {This study explores the use of vision foundation models to enhance 3D representations of cloth-like deformable objects. By focusing on the distillation of semantic information from RGB images, we examine the potential of pre-trained Visual-Language Models in capturing complex folded configurations of cloth. Our investigation reveals the challenges and preliminary successes in leveraging semantic information to improve the understanding and tracking of deformable object states.},
year={2024},
html={https://openreview.net/forum?id=1mwJlHsS19},
url={https://openreview.net/forum?id=1mwJlHsS19},
selected={true},
preview={distilling_semantic.png}
}
